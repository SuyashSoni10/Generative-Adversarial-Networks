{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]  D Loss: 0.1504  G Loss: 3.9082\n",
      "Epoch [2/20]  D Loss: 0.6844  G Loss: 2.3826\n",
      "Epoch [3/20]  D Loss: 1.1067  G Loss: 2.6726\n",
      "Epoch [4/20]  D Loss: 0.6959  G Loss: 4.4931\n",
      "Epoch [5/20]  D Loss: 0.2052  G Loss: 3.4598\n",
      "Epoch [6/20]  D Loss: 0.1995  G Loss: 2.9064\n",
      "Epoch [7/20]  D Loss: 0.2921  G Loss: 3.9876\n",
      "Epoch [8/20]  D Loss: 0.2943  G Loss: 7.8975\n",
      "Epoch [9/20]  D Loss: 0.2136  G Loss: 4.7095\n",
      "Epoch [10/20]  D Loss: 0.1457  G Loss: 6.3043\n",
      "Epoch [11/20]  D Loss: 0.4137  G Loss: 5.1909\n",
      "Epoch [12/20]  D Loss: 0.4034  G Loss: 4.6716\n",
      "Epoch [13/20]  D Loss: 0.1770  G Loss: 4.1958\n",
      "Epoch [14/20]  D Loss: 0.2680  G Loss: 3.8860\n",
      "Epoch [15/20]  D Loss: 0.3845  G Loss: 4.3139\n",
      "Epoch [16/20]  D Loss: 0.1789  G Loss: 4.7628\n",
      "Epoch [17/20]  D Loss: 0.2977  G Loss: 3.4236\n",
      "Epoch [18/20]  D Loss: 0.3295  G Loss: 4.3838\n",
      "Epoch [19/20]  D Loss: 0.4413  G Loss: 4.0398\n",
      "Epoch [20/20]  D Loss: 0.2043  G Loss: 3.7852\n",
      "Generator model saved!\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 150\n",
    "image_dim = 28 * 28  # MNIST images are 28x28\n",
    "batch_size = 60\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 50\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, image_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, image_dim),\n",
    "            nn.Tanh()  # Output values in range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()  # Output a probability\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(latent_dim, image_dim).to(device)\n",
    "discriminator = Discriminator(image_dim).to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Scale images to range [-1, 1]\n",
    "])\n",
    "dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real_images, _) in enumerate(data_loader):\n",
    "        # Flatten images and move to device\n",
    "        real_images = real_images.view(-1, image_dim).to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        # Labels for real and fake data\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_images = generator(z)\n",
    "        \n",
    "        real_loss = criterion(discriminator(real_images), real_labels)\n",
    "        fake_loss = criterion(discriminator(fake_images.detach()), fake_labels)\n",
    "        d_loss = real_loss + fake_loss\n",
    "\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Train Generator\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_images = generator(z)\n",
    "        g_loss = criterion(discriminator(fake_images), real_labels)  # Fool the discriminator\n",
    "\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  D Loss: {d_loss.item():.4f}  G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "# Save the trained generator model\n",
    "torch.save(generator.state_dict(), \"generator_2.pth\")\n",
    "print(\"Generator model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the trained generator model (if not already loaded)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mgenerator\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator_2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      5\u001b[0m generator\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Generate random noise and create fake images\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained generator model (if not already loaded)\n",
    "generator.load_state_dict(torch.load(\"generator_2.pth\"))\n",
    "generator.eval()\n",
    "\n",
    "# Generate random noise and create fake images\n",
    "z = torch.randn(16, latent_dim).to(device)  # Generate 16 samples\n",
    "fake_images = generator(z).detach().cpu()  # Detach from computation graph\n",
    "\n",
    "# Reshape and scale images back to [0, 1]\n",
    "fake_images = fake_images.view(-1, 28, 28)\n",
    "fake_images = (fake_images + 1) / 2.0\n",
    "\n",
    "# Plot the generated images\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(fake_images[i], cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
